- Words
  - T-Test =
    - evaluates whether there is a _significant differences_ between the *means* of 2 groups
    - between metric variables (measurable)
      - variable must be =normally distributed=
      - variance between groups must be ~=
    - Types:
      1) One Sample: compare it with a known mean value
      2) Independient Samples: we compare means of 2 _independient_ groups
      3) Paired Samples: we compare the means of 2 _dependent_ groups
  - Maximum Likelihood Estimation = ???
    - A way to find hyperparameters (?
  - Overfitting = tendency to memorize training data
  - Ground Truth = real life observations
  - Model = our prediction f(x)
  - Loss = prediction's error rate with our Ground Truth
  - Bias = a shift
  - Linearly Separable
    - if it can be partitioned by a straight line (or a plane or...)
  - Perceptron = the original Supervised Learning system
    - no Gradient Descent
    - binary classifier
    - good fit for *Linearly Separable* data
  - Training =
    - first phase of a ML system
  - Classification =
    - result is a categorical label
    - a type of prediction
      - final phase of a ML system
  - Sigmoid
    - fn in the [0:1] range
    - can act as a *Activation Function*
  - Hyperparameters = parameters to our train()
  - Hyperspaces = aka >3D dimensional spaces
  - Mean Squared Error = a way to calculate Loss
  - Log Loss = a way to calculate loss, works better with Sigmoid
  - Gradient Descent = a way to search for the minimum to our loss() aka train()
    - Gradient = curve of the loss
    - Partial Derivatives = a way to calculate Gradient Descend with multiple variables

- Types:
  - ~Reinforment Learning~: we want to optimize something
    - we only know in *relative* terms how good/bad a solution is
    - eg: an AI that "learns" to play a game by playing
  - ~Supervised Learning~: we provide *labeled* data.
    - By =function approximation= f(x)
    - A label can be a value.
    - Divided in phases:
      1. Training: finding f(x)
      2. Prediction: using f(x)
    - Linear Regression: w=weight b=bias
      $${y} = {x}*{w} + {b}$$
    - Multiple Linear Regression: for multiple inputs +1
      $${y} = {x_1}{w_1} + {x_2}{w_2} + {...} + {b}$$
  - ~Unsupervised Learning~: from *unlabeled* data
    - it learns about the relationships between the inputs provided.
    - Used for _clustering_ into groups.
    - Used to improve the quality of data.
    - Used for compress data.

- article: https://karpathy.github.io/2019/04/25/recipe/
- article: llm agent https://tadeodonegana.com/posts/building-agents-my-notes/
- https://github.com/AudioLLMs/AudioLLM
- https://microsoft.github.io/generative-ai-for-beginners/#/
- https://uvadlc-notebooks.readthedocs.io/en/latest/index.html
- https://stackoverflow.blog/2022/04/21/the-robots-are-coming-for-the-boring-parts-of-your-job/?cb=1
- http://karpathy.github.io/neuralnets/
- Andrew Ng https://www.coursera.org/learn/machine-learning
- CS231n: Convolutional Neural Networks for Visual Recognition http://vision.stanford.edu/teaching/cs231n/
- https://twitter.com/cfiesler/status/1336317217034612737
  Algorithms of Oppresion
  The Age of Surveillance Capitalism
  Race After Technology
  Weapons of Math Destruction
  Automating Inequality
  Technically Wrong
  Ghost Work
  Design Justice
- https://ml4code.github.io/papers.html
- https://medium.com/@satnalikamayank12/on-automated-generation-of-commit-messages-from-code-differences-7ab205ae580
- https://www.edx.org/course/artificial-intelligence-for-everyone
- https://github.com/mrdbourke/machine-learning-roadmap
- https://github.com/visenger/awesome-mlops
- https://github.com/mitmath/18337
- Toward ethical, transparent and fair AI/ML:
  a critical reading list for engineers, designers, and policy makers
  https://github.com/rockita/criticalML

* DataSets

- https://github.com/shramos/Awesome-Cybersecurity-Datasets
- https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research
- https://en.wikipedia.org/wiki/List_of_datasets_in_computer_vision_and_image_processing
- https://en.wikipedia.org/wiki/Iris_flower_data_set
- https://en.wikipedia.org/wiki/ImageNet
- https://github.com/several27/FakeNewsCorpus
- https://en.wikipedia.org/wiki/MNIST_database
  - Modified NIST (National Institute of Standards and Technology)
  - 28x28 grayscale
  - 1 byte pixels
    - 0x00 white
    - 0xff black
  - 70k examples
    - 7k per digit
    - 4 files
      - 60k images for training
      - 60k labels
      - 10k images for testing
      - 10k labels
